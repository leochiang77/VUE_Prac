utils/processing_img.py

import cv2
import numpy as np
from PIL import Image, ImageEnhance


DEFAULT_THRESHOLD = 45
DEFAULT_MORPH_KERNEL = np.ones((3, 3), np.uint8)
DEFAULT_BILATERAL_PARAMETERS = (7, 150, 150)


class ProcessImg:
    def __init__(self, original_img: np.ndarray, img_scale: float):
        """
        初始化 ProcessImg 類別。

        參數:
            original_img (np.ndarray): 原始圖像，必須是 BGR 格式。
            img_scale (float): 用於縮放圖像的比例因子。
        """
        self.img_scale = img_scale
        self.original_img = original_img
        self.images = self.process_images()

    def process_images(self) -> dict:
        """
        處理圖像，包括增強、灰階轉換、模糊、邊緣檢測、雙邊濾波、二值化和形態學操作。

        返回:
            dict: 包含各步驟處理後的圖像字典，包括原始圖像、灰階圖像、模糊圖像、拉普拉斯圖像、
                  雙邊濾波圖像、二值化圖像、形態學處理圖像和縮放後的圖像。
        """
        images = {}
        images["original_img"] = self.original_img.copy()

        # 圖片增強
        # enhanced_img = enhance_image(self.original_img)
        enhanced_img = sharpen(self.original_img, sigma=100)

        # 將圖像轉換為灰度圖
        gray_image = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2GRAY)
        images["gray"] = gray_image

        # 高斯模糊平滑圖
        blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)
        images["blur"] = blurred_image

        # 拉普拉斯核進行邊緣檢測
        laplacian_image = cv2.Laplacian(blurred_image, -1, 1, 5)
        laplacian_image = cv2.convertScaleAbs(laplacian_image)
        images["laplacian"] = laplacian_image

        # 雙邊濾波
        bilateral_filtered = cv2.bilateralFilter(
            laplacian_image, *DEFAULT_BILATERAL_PARAMETERS)
        images["bilateral"] = bilateral_filtered

        # 二值化處理
        _, binary = cv2.threshold(
            bilateral_filtered, DEFAULT_THRESHOLD, 255, cv2.THRESH_BINARY_INV)
        images["binary"] = binary

        # 形態學操作：膨脹和腐蝕
        morp_image = cv2.morphologyEx(
            binary, cv2.MORPH_CLOSE, DEFAULT_MORPH_KERNEL, iterations=1)
        images["morp"] = morp_image

        # 放大U shape
        resize_img = self.scale_image(morp_image)
        images["resize"] = resize_img

        return images

    def get_clear_img(self) -> np.ndarray:
        """
        獲取處理後的清晰圖像（即放大後的圖像）。

        返回:
            np.ndarray: 放大後的圖像。
        """
        return self.images["resize"]

    def get_mop_img(self) -> np.ndarray:
        """
        獲取形態學處理後的圖像。

        返回:
            np.ndarray: 形態學處理後的圖像。
        """
        return self.images["morp"]

    def get_images(self) -> dict:
        """
        獲取所有處理過的圖像。

        返回:
            dict: 包含各步驟處理後的圖像的字典。
        """
        return self.images

    def scale_image(self, need_image: np.ndarray) -> np.ndarray:
        """
        從中心放大圖像。

        參數:
            need_image (np.ndarray): 需要縮放的圖像。

        返回:
            np.ndarray: 縮放後的圖像。
        """

        height, width = need_image.shape[:2]
        center_x, center_y = width // 2, height // 2

        x_start = max(0, center_x - int(width / (2 * self.img_scale)))
        x_end = min(width, center_x + int(width / (2 * self.img_scale)))
        y_start = max(0, center_y - int(height / (2 * self.img_scale)))
        y_end = min(height, center_y + int(height / (2 * self.img_scale)))

        cropped_image = need_image[y_start:y_end, x_start:x_end]
        resize_image = cv2.resize(
            cropped_image, (width, height), interpolation=Image.BICUBIC)

        return resize_image


def enhance_image(img_cv2: np.ndarray, sharpness_factor: float = 2.0, contrast_factor: float = 1.5) -> np.ndarray:
    """
    增強圖像的銳度和對比度。

    參數:
        img_cv2 (np.ndarray): 原始 BGR 格式圖像。
        sharpness_factor (float): 銳度增強因子（默認為 2.0）。
        contrast_factor (float): 對比度增強因子（默認為 1.5）。

    返回:
        np.ndarray: 增強後的 BGR 格式圖像。
    """

    img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)

    pil_img = Image.fromarray(img_rgb)

    sharpness_enhancer = ImageEnhance.Sharpness(pil_img)
    pil_img_sharp = sharpness_enhancer.enhance(sharpness_factor)

    contrast_enhancer = ImageEnhance.Contrast(pil_img_sharp)
    pil_img_contrast = contrast_enhancer.enhance(contrast_factor)

    enhanced_img_cv2 = cv2.cvtColor(
        np.array(pil_img_contrast), cv2.COLOR_RGB2BGR)

    return enhanced_img_cv2


def sharpen(img: np.ndarray, sigma: float = 100) -> np.ndarray:
    """
    使用高斯模糊和加權來進行圖像銳化。

    參數:
        img (np.ndarray): 原始 BGR 格式圖像。
        sigma (float): 高斯模糊的標準差（默認為 100）。

    返回:
        np.ndarray: 銳化後的 BGR 格式圖像。
    """
    # sigma = 5、15、25
    blur_img = cv2.GaussianBlur(img, (0, 0), sigma)
    usm = cv2.addWeighted(img, 1.5, blur_img, -0.5, 0)

    return usm

-------------------------------------------------------------------------------------
utils/offset_img.py

import numpy as np
import cv2
from PIL import Image

from utils import tools


class OffsetImg:
    def __init__(self, image: np.ndarray, image_id: str, json_path: str, max_point: int = 5,
                 box_size: int = 100, min_black_line: float = 0.2, center_circle_radii: int = 5,
                 max_offset_pixels: int = 65):
        """
        初始化 OffsetImg 類別。

        參數:
            image (np.ndarray): 輸入圖像。
            image_id (str): 圖像ID，用於加載相關的框點和方向。
            json_path (str): JSON 配置文件的路徑。
            max_point (int): 最大點數（默認為 5）。
            box_size (int): 盒子大小（默認為 100）。
            min_black_line (float): 最小黑線比例（默認為 0.2）。
            center_circle_radii (int): 圓心半徑（默認為 5）。
            max_offset_pixels (int): 最大偏移像素（默認為 65）。
        """

        self.image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        self.max_point = max_point
        self.box_size = box_size
        self.min_black_line = min_black_line
        self.center_circle_radii = center_circle_radii
        self.max_offset_pixels = max_offset_pixels

        self.init_box_points, self.init_directions_points = tools.load_box(
            image_id, json_path)

    def _find_best_shift(self) -> tuple:
        """
        查找最佳的圖像偏移量。

        返回:
            Tuple[Tuple[int, int], int]: 包含最佳偏移量和最佳白色像素總數的元組。
        """

        best_shift = (0, 0)
        best_total_white = 0

        for shift_x in range(-self.max_offset_pixels, self.max_offset_pixels + 1, 2):
            for shift_y in range(-self.max_offset_pixels, self.max_offset_pixels + 1, 2):
                shifted_image = self._shift_image(self.image, shift_x, shift_y)
                total_white = self._count_vaild_pixels(
                    shifted_image=shifted_image)

                if total_white > best_total_white:
                    best_total_white = total_white
                    best_shift = (shift_x, shift_y)
                if best_total_white >= self.max_point:
                    break
            if best_total_white >= self.max_point:
                break

        return best_shift, best_total_white

    def _shift_image(self, image: np.ndarray, shift_x: int, shift_y: int, color: int = 0) -> np.ndarray:
        """
        偏移圖像。

        參數:
            image (np.ndarray): 輸入圖像。
            shift_x (int): 水平偏移量。
            shift_y (int): 垂直偏移量。
            color (int): 偏移區域的顏色（默認為 0）。

        返回:
            np.ndarray: 偏移處理後的圖像。
        """

        shifted_image = np.roll(image, shift_x, axis=1)
        shifted_image = np.roll(shifted_image, shift_y, axis=0)

        if shift_x > 0:
            shifted_image[:, :shift_x] = color
        elif shift_x < 0:
            shifted_image[:, shift_x:] = color

        if shift_y > 0:
            shifted_image[:shift_y, :] = color
        elif shift_y < 0:
            shifted_image[shift_y:, :] = color

        return shifted_image

    def _count_vaild_pixels(self, shifted_image: np.ndarray) -> int:
        """
        計算偏移圖像中有效的白色像素數量。

        參數:
            shifted_image (np.ndarray): 偏移處理後的圖像。

        返回:
            int: 有效的白色像素數量。
        """
        total_white = 0
        for point, direction in zip(self.init_box_points, self.init_directions_points):
            center = (point[0], point[1])
            is_circle = tools.is_circle_white(shifted_image, center,
                                              self.center_circle_radii)
            is_line = tools.is_black_line(
                shifted_image, (point[0], point[1]), direction=direction, len_size=self.box_size, min_black_line_threadhld=self.min_black_line)
            if is_circle:
                if is_line:
                    total_white += 1
        return total_white

    def get_shift_img(self, image: np.ndarray, img_scale: float) -> tuple:
        """
        獲取偏移後的圖像。

        參數:
            image (np.ndarray): 輸入圖像。
            img_scale (float): 圖像縮放比例。

        返回:
            Tuple[np.ndarray, int]: 包含偏移處理後的圖像和最佳白色像素數量的元組。
        """

        best_shift, best_total_white = self._find_best_shift()
        print("Best shift (x, y):", best_shift)
        print("Total white with best shift:", best_total_white)

        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        padding = self.max_offset_pixels

        # create canvas
        o_height, o_width = image.shape[:2]
        large_canvas = np.zeros(
            (o_height + 2 * padding, o_width + 2 * padding, 3), dtype=np.uint8)
        large_canvas[padding:padding + o_height,
                     padding:padding + o_width] = image

        # scale
        c_height, c_width = large_canvas.shape[:2]
        center_x, center_y = c_width // 2, c_height // 2

        x_start = max(0, center_x - int(c_width / (2 * img_scale)))
        x_end = min(c_width, center_x + int(c_width / (2 * img_scale)))
        y_start = max(0, center_y - int(c_height / (2 * img_scale)))
        y_end = min(c_height, center_y + int(c_height / (2 * img_scale)))

        cropped_image = large_canvas[y_start:y_end, x_start:x_end]
        resize_image = cv2.resize(
            cropped_image, (c_width, c_height), interpolation=Image.BICUBIC)

        # shift
        M = np.float32([[1, 0, best_shift[0]], [0, 1, best_shift[1]]])
        shifted_image = cv2.warpAffine(
            resize_image, M, (c_width, c_height), borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))

        # crop to original img
        cropped_image = shifted_image[padding:padding +
                                      o_height, padding:padding + o_width]

        # if show_line:
        #     cropped_image = self.draw_circles(cropped_image)

        return cropped_image, best_total_white

    def draw_circles(self, image_rgb: np.ndarray) -> np.ndarray:
        """
        在圖像上繪製圓圈和線條。

        參數:
            image_rgb (np.ndarray): 要繪製的圖像。

        返回:
            np.ndarray: 繪製圓圈和線條後的圖像。
        """
        for point, direction in zip(self.init_box_points, self.init_directions_points):
            center = (point[0], point[1])
            cv2.circle(image_rgb, center,
                       self.center_circle_radii, (0, 255, 0), 2)
            tools.draw_helf_line(image_rgb, center, direction, self.box_size)

        return image_rgb


class offsetImgbyModel():
    def __init__(self, image: np.ndarray, template_img: np.ndarray, max_offset_pixels: int = 65):
        """
        初始化 OffsetImgByModel 類別。

        參數:
            image (np.ndarray): 輸入圖像。
            template_img (np.ndarray): 模板圖像。
            max_offset_pixels (int): 最大偏移像素（默認為 65）。
        """
        self.image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        self.template_img = cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)
        self.max_offset_pixels = max_offset_pixels

    def _find_best_shift(self) -> tuple:
        """
        查找最佳的模型偏移量。

        返回:
            Tuple[Tuple[int, int], float]: 包含最佳偏移量和最佳匹配得分的元組。
        """
        best_offset = (0, 0)
        best_score = -np.inf

        for y_offset in range(-self.max_offset_pixels, self.max_offset_pixels + 1, 2):
            for x_offset in range(-self.max_offset_pixels, self.max_offset_pixels + 1, 2):
                # Calculate the offset img position
                M = np.float32([[1, 0, x_offset], [0, 1, y_offset]])
                shifted_template = cv2.warpAffine(
                    self.template_img, M, (self.image.shape[1], self.image.shape[0]))

                # Calculate match
                score = np.sum((self.image == shifted_template)
                               & (shifted_template == 0))

                # Update optimal offset and score
                if score > best_score:
                    best_score = score
                    best_offset = (x_offset, y_offset)
        return best_offset, best_score

    def get_shift_model_img(self) -> np.ndarray:
        """
        獲取最佳偏移後的模型圖像。

        返回:
            np.ndarray: 最佳偏移後的模型圖像。
        """
        best_offset, best_score = self._find_best_shift()
        print(f"Model Best offset: {best_offset}, suitability: {best_score}")

        M = np.float32([[1, 0, best_offset[0]], [0, 1, best_offset[1]]])
        best_shifted_template = cv2.warpAffine(
            self.template_img, M, (self.image.shape[1], self.image.shape[0]), borderValue=(255, 255, 255))

        return best_shifted_template

-------------------------------------------------------------------------------------
utils/fill_vacancy_img.py

import cv2
import numpy as np


class FillImg():
    """
    修復受損圖像的類別，通過模板圖像填補缺陷。

    屬性:
        template_img (np.ndarray): 模板圖像。
        damaged_img (np.ndarray): 受損圖像。
    """

    def __init__(self, template_img: np.ndarray, damaged_img: np.ndarray):
        """
        初始化 FillImg 類別。

        參數:
            template_img (np.ndarray): 模板圖像。
            damaged_img (np.ndarray): 受損圖像。
        """
        self.template_img = template_img
        self.damaged_img = damaged_img

    def repair_image(self) -> np.ndarray:
        """
        修復受損圖像。

        返回:
            np.ndarray: 修復後的圖像。
        """

        if self.template_img.shape[:2] != self.damaged_img.shape[:2]:
            raise Exception(
                "Template and damaged image must have the same dimensions.")

        # erode template
        erode_template_img = self._erode_template()
        damaged_img_gray = cv2.cvtColor(self.damaged_img, cv2.COLOR_BGR2GRAY)

        # find white defeat
        defeats_img = self._find_defeats(
            erode_template_img, damaged_img_gray=damaged_img_gray)
        # cv2.imshow("defeats_img", defeats_img)

        repair_image = np.where((defeats_img == 0) | (
            damaged_img_gray == 0), 0, 255).astype(np.uint8)

        return repair_image

    def _erode_template(self) -> np.ndarray:
        """
        腐蝕模板圖像以縮小和去除邊緣。

        返回:
            np.ndarray: 腐蝕後的模板圖像。
        """

        inv_template_img = cv2.bitwise_not(self.template_img)
        inv_template_img = cv2.erode(
            inv_template_img, np.ones((6, 6), np.uint8), iterations=2)
        inv_template_img = cv2.bitwise_not(inv_template_img)
        # cv2.imshow("inv_template_img", inv_template_img)
        return inv_template_img

    def _find_defeats(self, erode_template_img: np.ndarray, damaged_img_gray: np.ndarray) -> np.ndarray:
        """
        找到模板圖像和受損圖像之間的不同像素。

        參數:
            erode_template_img (np.ndarray): 腐蝕後的模板圖像。
            damaged_img_gray (np.ndarray): 受損圖像的灰階圖像。

        返回:
            np.ndarray: 顯示缺陷區域的圖像。
        """

        # need template has black pixels and damaged not
        miss_img = np.where((erode_template_img == 0) & (
            damaged_img_gray == 255), 0, 255).astype(np.uint8)

        # remove noise
        img_blur = cv2.morphologyEx(
            miss_img, cv2.MORPH_CLOSE, np.ones((4, 4), np.uint8))
        # cv2.imshow("img_blur", img_blur)

        # Connected component analysis
        min_area = 200
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
            255 - img_blur, connectivity=8)
        img_filtered = np.zeros_like(img_blur)
        for label in range(1, num_labels):
            if stats[label, cv2.CC_STAT_AREA] >= min_area:
                img_filtered[labels == label] = 255

        img_filtered = cv2.dilate(
            img_filtered, np.ones((5, 5), np.uint8), iterations=1)
        img_filtered = cv2.bitwise_not(img_filtered)

        return img_filtered

-------------------------------------------------------------
utils/generate_box.py

from utils import tools
import cv2
import random
import numpy as np
# import matplotlib.pyplot as plt


class GenerateBox:
    def __init__(self, image: np.ndarray, image_id: str, json_path: str, box_size: int = 100,
                 min_black_line: float = 0.2, center_circle_radii: int = 5,
                 box_scale_range: int = 20, max_IOU_area_prop: float = 0.4, min_black_area_prop: float = 0.3, try_error_times: int = 500):
        """
        初始化 GenerateBox 類別的實例。

        參數:
            image (np.ndarray): 輸入的灰階圖像。
            image_id (str): 圖像的唯一標識符。
            json_path (str): JSON 文件的路徑，包含初始的盒子資訊。
            box_size (int): 盒子的大小（默認為 100）。
            min_black_line (float): 盒子中最小黑線的閾值（默認為 0.2）。
            center_circle_radii (int): 盒子中心圓的半徑（默認為 5）。
            box_scale_range (int): 盒子大小調整的範圍（默認為 20）。
            max_IOU_area_prop (float): 最大的 IOU 面積比例（默認為 0.4）。
            min_black_area_prop (float): 盒子中最小黑色區域的比例（默認為 0.3）。
            try_error_times (int): 嘗試生成有效盒子的最大次數（默認為 500）。
        """
        self.image = image
        self.rgb_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)

        self.box_size = box_size
        self.min_black_line = min_black_line
        self.center_circle_radii = center_circle_radii
        self.box_scale_range = box_scale_range
        self.max_IOU_area_prop = max_IOU_area_prop
        self.min_black_area_prop = min_black_area_prop

        self.try_error_times = try_error_times

        self.init_box_points, self.init_directions = tools.load_box(
            image_id, json_path)

        self.valid_top_points = []

    def calculate_positions(self, box_num: int = 5) -> tuple:
        """
        計算盒子的位置。

        參數:
            box_num (int): 需要生成的盒子數量（默認為 5）。

        返回:
            tuple: 包含兩個元素的元組：
                - adjust_positions (list of tuple): 生成的盒子位置列表，每個位置是 (x, y) 的元組。
                - adjust_sizes (list of int): 生成的盒子大小列表。
        """

        b_size = self.box_size
        height, width = self.image.shape[:2]
        box_points = self.init_box_points

        adjust_sizes = [b_size]*box_num
        adjust_positions = box_points.copy()

        # Ensure we have space to place the box
        if height < b_size or width < b_size:
            raise Exception("Image is too small for the specified box size.")

        # Ensure has run settings
        if box_points is None:
            raise Exception("Please run [run_settings_box.py] first.")

        invalid_index = []

        # save valid box
        for i, (point, direction) in enumerate(zip(box_points, self.init_directions)):

            top_x = point[0]-b_size//2
            top_y = point[1]-b_size//2

            # base condictions for init box
            if self._is_valid_box(point=point, direction=direction, left_top_point=(top_x, top_y), valid_top_points=self.valid_top_points):
                is_discon, adjust_size = self._scale_valid_box(point)
                # scale condition
                if is_discon is True:
                    self.valid_top_points.append((top_x, top_y))
                    adjust_sizes[i] = adjust_size

                else:
                    invalid_index.append(i)
                    print(
                        f"box {i+1} scale condition invaild {adjust_size}, it will be generated by new random box.")

            else:
                invalid_index.append(i)
                print(
                    f"box {i+1} base condition invaild, it will be generated by new random box.")

        # If still invalid, create a new point
        times = self.try_error_times
        while invalid_index != []:
            # print(invalid_index)
            # if times < 0 and len(invalid_index) != 1:
            #     invalid_index.pop(0)
            #     times = 500
            if times < 0:
                raise Exception(
                    "Generate box time out. This picture can't be used.")
            new_point = self._create_point_in_contour(
                adjust_positions[invalid_index[0]])
            new_top_x = new_point[0]-self.box_size//2
            new_top_y = new_point[1]-self.box_size//2

            if self._is_valid_box(point=new_point, direction=self.init_directions[invalid_index[0]], left_top_point=(
                    new_top_x, new_top_y), valid_top_points=self.valid_top_points):

                new_is_discon, new_adjust_size = self._scale_valid_box(
                    new_point)

                # scale condition
                if new_is_discon is True:
                    self.valid_top_points.append((new_top_x, new_top_y))

                    adjust_positions[invalid_index[0]] = new_point
                    adjust_sizes[invalid_index[0]] = new_adjust_size
                    print(
                        f"box {invalid_index[0]+1} has been generated by new random point:{(new_top_x, new_top_y)}.")

                    invalid_index.pop(0)
                    times = self.try_error_times
                else:
                    times -= 1

            else:
                times -= 1

        return adjust_positions, adjust_sizes

    def draw_contours(self, adjust_positions: list, adjust_sizes: list) -> np.ndarray:
        """
        在圖像上繪製盒子輪廓。

        參數:
            adjust_positions (list of tuple): 盒子的位置列表，每個位置是 (x, y) 的元組。
            adjust_sizes (list of int): 盒子的大小列表。

        返回:
            np.ndarray: 包含繪製了盒子輪廓的 RGB 圖像。
        """

        rgb_img = self.rgb_image.copy()
        for i, (point, direction, adj_size) in enumerate(zip(adjust_positions, self.init_directions, adjust_sizes)):

            tools.draw_box(image=rgb_img,
                           center_point=point, box_num=i, frame_size=adj_size, direction=direction)
            top_x = point[0]-adj_size//2
            top_y = point[1]-adj_size//2
            box_rgb = rgb_img[top_y:top_y + adj_size,
                              top_x:top_x + adj_size]

            max_contour = tools.get_max_contour(self.image, point, adj_size)
            if max_contour is not None:
                cv2.drawContours(box_rgb, [max_contour], -1,
                                 color=(0, 255, 0), thickness=2)
        return rgb_img

    def _is_valid_box(self, point: tuple, direction: any, left_top_point: tuple, valid_top_points: list) -> bool:
        """
        檢查指定位置的盒子是否有效。

        參數:
            point (tuple): 盒子的中心點 (x, y)。
            direction (any): 盒子的方向。
            left_top_point (tuple): 盒子的左上角 (x, y)。
            valid_top_points (list of tuple): 已驗證的盒子位置列表。

        返回:
            bool: 盒子是否有效。
        """

        if not tools.is_circle_white(
                self.rgb_image, point, self.center_circle_radii):
            return False

        if direction is not None:
            if not tools.is_black_line(self.rgb_image, point, direction, self.box_size, self.min_black_line):
                return False

        box = self.image[left_top_point[1]:left_top_point[1] + self.box_size,
                         left_top_point[0]:left_top_point[0] + self.box_size]

        if not tools.has_sufficient_black_pixels(box, self.min_black_area_prop):
            return False

        if tools.is_overlapping(left_top_point, valid_top_points, self.box_size, self.max_IOU_area_prop):
            return False

        return True

    def _cal_discon_white(self, point: tuple, adj_size: int) -> tuple:
        """
        計算盒子中不連續的白色像素數量。

        參數:
            point (tuple): 盒子的中心點 (x, y)。
            adj_size (int): 盒子的大小。

        返回:
            tuple: 包含兩個元素的元組：
                - bool: 是否有兩個不連續的白色區域。
                - dict: 每個邊的不連續白色像素數量的字典。
        """
        def count_discontinuous_whites(edge):
            count = 0
            in_white_region = False
            for pixel in edge:
                if pixel == 255:  # White pixel
                    if not in_white_region:
                        count += 1
                        in_white_region = True
                else:
                    in_white_region = False
            return count

        max_contour = tools.get_max_contour(self.image, point, adj_size)
        top_x = point[0]-adj_size//2
        top_y = point[1]-adj_size//2

        box = self.image[top_y:top_y + adj_size,
                         top_x:top_x + adj_size]

        mask = np.zeros_like(box, dtype=np.uint8)
        if max_contour is not None:
            cv2.drawContours(mask, [max_contour], -1,
                             255, thickness=cv2.FILLED)

        # Calculate discontinuous white pixels along each edge
        top_edge = mask[0, :]
        bottom_edge = mask[-1, :]
        left_edge = mask[:, 0]
        right_edge = mask[:, -1]

        # Count discontinuous white pixels
        top_discontinuous = count_discontinuous_whites(top_edge)
        bottom_discontinuous = count_discontinuous_whites(bottom_edge)
        left_discontinuous = count_discontinuous_whites(left_edge)
        right_discontinuous = count_discontinuous_whites(right_edge)

        discontinuous = {
            'top_discontinuous': top_discontinuous,
            'bottom_discontinuous': bottom_discontinuous,
            'left_discontinuous': left_discontinuous,
            'right_discontinuous': right_discontinuous
        }
        sum_discontinuous = top_discontinuous + bottom_discontinuous +\
            left_discontinuous + right_discontinuous

        '''test draw'''
        # plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))
        # plt.show()
        # cv2.drawContours(self.rgb_image[top_y:top_y + adj_size,
        #                                 top_x:top_x + adj_size], [max_contour], -1,
        #                  color=(0, 0, 255), thickness=1)
        # plt.imshow(cv2.cvtColor(self.rgb_image, cv2.COLOR_BGR2RGB))
        # plt.show()

        return sum_discontinuous == 2, discontinuous

    def _create_point_in_contour(self, point: tuple) -> tuple:
        """
        在輪廓內隨機創建一個新的點。

        參數:
            point (tuple): 盒子的中心點 (x, y)。

        返回:
            tuple: 隨機生成的新點 (x, y)。
        """
        top_x = point[0]-self.box_size//2
        top_y = point[1]-self.box_size//2
        img_h, img_w = self.image.shape[:2]

        is_white = False
        random_point_global = point

        max_contour = tools.get_max_contour(self.image, point, self.box_size)

        if max_contour is not None:
            x, y, w, h = cv2.boundingRect(max_contour)

            while not is_white:
                rx, ry = (random.randint(x, x + w - 1),
                          random.randint(y, y + h - 1))
                random_point = (max(min(rx, img_w - self.box_size - 1), 0),
                                max(min(ry, img_h - self.box_size - 1), 0))

                random_point_global = (
                    top_x + random_point[0], top_y + random_point[1])

                is_white = self.image[random_point_global[1],
                                      random_point_global[0]] != 0

        '''test draw'''
        # print("Random point within contour:", random_point_global, is_white)
        # cv2.circle(self.rgb_image, random_point_global, radius=4,
        #            color=(255, 0, 0), thickness=1)

        return random_point_global

    def _scale_valid_box(self, point: tuple) -> tuple:
        """
        調整盒子的大小以滿足不連續白色像素的條件。

        參數:
            point (tuple): 盒子的中心點 (x, y)。

        返回:
            tuple: 包含兩個元素的元組：
                - bool: 調整後的盒子是否有效。
                - int: 調整後的盒子大小。
        """
        adjust_size = self.box_size
        is_discon, _ = self._cal_discon_white(point, adjust_size)

        # Adjust box size
        if not is_discon:
            for scale in range(-self.box_scale_range, self.box_scale_range + 1):
                adjust_size = self.box_size + scale

                # scale > image width/height
                if (point[0]-adjust_size//2) < 0 or (point[1]-adjust_size//2) < 0:
                    continue

                is_discon, _ = self._cal_discon_white(point, adjust_size)

                if is_discon:
                    break

        return is_discon, adjust_size

-------------------------------------------------------------------------
utils/calculate_width.py

from utils import tools
import numpy as np
import cv2


class CalculateWidth:
    """
    計算圖像中框的寬度。

    屬性:
        fill_image (np.ndarray): 填充圖像，通常為灰階圖像。
        positions (list of tuple): 框的中心點位置 (x, y)。
        sizes (list of int): 每個框的大小。
    """

    def __init__(self, fill_image: np.ndarray, positions: list, sizes: list):
        """
        初始化 CalculateWidth 類別。

        參數:
            fill_image (np.ndarray): 填充圖像，通常為灰階圖像。
            positions (list of tuple): 框的中心點位置 (x, y)。
            sizes (list of int): 每個框的大小。
        """
        self.fill_image = fill_image
        self.positions = positions
        self.sizes = sizes

        self.sp_contours = [None]*len(self.positions)
        self.lines = [None]*len(self.positions)

    def calculate_box_width(self) -> list:
        """
        計算每個框的寬度。

        返回:
            list: 每個框的平均寬度。
        """
        self._split_contours()
        distances = [None]*len(self.positions)

        for b_num, sp_contour in enumerate(self.sp_contours):
            # A to B
            box_lines_AtoB, box_min_distances_AtoB = self._single_beside(
                sp_contour[0], sp_contour[1])
            # B to A
            box_lines_BtoA, box_min_distances_BtoA = self._single_beside(
                sp_contour[1], sp_contour[0])

            # average
            box_min_distances = box_min_distances_AtoB+box_min_distances_BtoA
            average_distance = self._average_distance(box_min_distances)

            distances[b_num] = average_distance

            self.lines[b_num] = (box_lines_AtoB, box_lines_BtoA)
        return distances
    # split right and left

    def draw_beside_AB(self) -> np.ndarray:
        """
        繪製每個框及其邊界。

        返回:
            np.ndarray: 包含框及邊界的彩色圖像。
        """
        image_rgb = self.fill_image.copy()
        image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_GRAY2BGR)

        for i, (point, box_size) in enumerate(zip(self.positions, self.sizes)):
            top_x = point[0]-box_size//2
            top_y = point[1]-box_size//2
            box_rgb = image_rgb[top_y:top_y + box_size,
                                top_x:top_x + box_size]

            tools.draw_box(image=image_rgb,
                           center_point=point, box_num=i, frame_size=box_size, direction=None)

            cv2.drawContours(
                box_rgb, [self.sp_contours[i][0]], -1, (255, 0, 0), 2)
            cv2.drawContours(
                box_rgb, [self.sp_contours[i][1]], -1, (255, 255, 0), 2)

            for start_point, min_point in self.lines[i][0]:
                cv2.line(box_rgb, start_point, min_point, (0, 0, 255), 2)
            for start_point, min_point in self.lines[i][1]:
                cv2.line(box_rgb, start_point, min_point, (0, 0, 255), 2)

        return image_rgb

    def _single_beside(self, A: np.ndarray, B: np.ndarray) -> tuple:
        """
        計算單個框的邊界距離。

        參數:
            A (np.ndarray): 框 A 的輪廓點。
            B (np.ndarray): 框 B 的輪廓點。

        返回:
            tuple: 包含邊界線條和最小距離的列表。
        """
        box_min_distances = []
        box_lines = []
        for contour_A in A:
            start_point = np.squeeze(contour_A)
            min_distance = float('inf')
            min_point = None

            contour_B = B
            for j in range(len(contour_B)-1):
                end1_point = np.squeeze(contour_B[j])
                end2_point = np.squeeze(contour_B[j+1])

                center_point, distance = tools.calculate_point(
                    start_point, end1_point, end2_point)

                if distance < min_distance:
                    min_distance = distance
                    min_point = center_point
            box_lines.append((start_point, min_point))
            box_min_distances.append(min_distance)

        return box_lines, box_min_distances

    def _split_contours(self):
        """
        分割每個框的輪廓。
        """

        # calculate each box
        for i, (point, box_size) in enumerate(zip(self.positions, self.sizes)):

            max_contour = tools.get_max_contour(
                self.fill_image, point, box_size)

            if max_contour is None:
                continue

            # reordered contour by start with zero
            reordered_contour = self._dim_reordered_contour(max_contour)

            beside_A, beside_B = self._split_each_box(
                reordered_contour, box_size=box_size)

            self.sp_contours[i] = (beside_A, beside_B)

            '''test print'''
            # print("reordered:", reordered_contour)
            # print("beside_A", contours[i][0])
            # print("beside_B", contours[i][1])

            # contours[i] = max_contour

    def _dim_reordered_contour(self, contour: np.ndarray) -> np.ndarray:
        """
        重新排序輪廓，以使其從零點開始。

        參數:
            contour (np.ndarray): 輪廓點。

        返回:
            np.ndarray: 重新排序的輪廓。
        """
        # reduce dim
        contour = np.squeeze(contour)

        # find first x or y index
        idx = None
        for i, (x, y) in enumerate(contour):
            if x == 0 or y == 0:
                idx = i
                break

        if idx is None:
            return contour

        reordered = np.concatenate((contour[idx:], contour[:idx]))

        # reordered = np.expand_dims(reordered, axis=1)

        return reordered

    def _split_each_box(self, reordered_contour: np.ndarray, box_size: int) -> tuple:
        """
        分割每個框的輪廓為 A 和 B 兩部分。

        參數:
            reordered_contour (np.ndarray): 重新排序的輪廓點。
            box_size (int): 框的大小。

        返回:
            tuple: 兩部分輪廓點 (beside_A, beside_B)。
        """
        beside_A = np.empty((0, 2), dtype=int)
        beside_B = np.empty((0, 2), dtype=int)

        min_x = min_y = 0
        max_x = max_y = box_size-1
        flags = {'min_x': -1, 'max_x': -1, 'min_y': -1, 'max_y': -1}

        final_need_change = False
        has_changed = False
        now_beside_A = True
        tmp_current_side = None

        for idx, contour in enumerate(reordered_contour):
            # Calculate the number of boundaries
            x, y = contour
            if x == min_x:
                flags['min_x'] += 1
            elif x == max_x:
                flags['max_x'] += 1
            elif y == min_y:
                flags['min_y'] += 1
            elif y == max_y:
                flags['max_y'] += 1

            # special exception
            if now_beside_A and tmp_current_side is not None:
                if flags['min_x'] == -98:
                    beside_A[-1] = contour
                    flags['min_x'] -= 1
                    continue
                elif flags['max_x'] == -98:
                    beside_A[-1] = contour
                    flags['max_x'] -= 1
                    continue
                elif flags['min_y'] == -98:
                    beside_A[-1] = contour
                    flags['min_y'] -= 1
                    continue
                elif flags['max_y'] == -98:
                    beside_A[-1] = contour
                    flags['max_y'] -= 1
                    continue
            elif tmp_current_side is not None:
                if flags['min_x'] == -98:
                    beside_B[-1] = contour
                    flags['min_x'] -= 1
                    continue
                elif flags['max_x'] == -98:
                    beside_B[-1] = contour
                    flags['max_x'] -= 1
                    continue
                elif flags['min_y'] == -98:
                    beside_B[-1] = contour
                    flags['min_y'] -= 1
                    continue
                elif flags['max_y'] == -98:
                    beside_B[-1] = contour
                    flags['max_y'] -= 1
                    continue

            # If there are more than two, turn aside.
            if flags['min_x'] == 1 or flags['max_x'] == 1 or flags['min_y'] == 1 or flags['max_y'] == 1:

                if idx == 1:
                    final_need_change = True

                if flags['min_x'] == 1:
                    flags['min_x'] = -99
                elif flags['max_x'] == 1:
                    flags['max_x'] = -99
                elif flags['min_y'] == 1:
                    flags['min_y'] = -99
                elif flags['max_y'] == 1:
                    flags['max_y'] = -99

                if not has_changed:
                    now_beside_A = not now_beside_A
                    has_changed = True
                elif has_changed and final_need_change:
                    now_beside_A = not now_beside_A

                tmp_current_side = contour
            else:
                tmp_current_side = None

            # Current Beside
            if now_beside_A:
                beside_A = np.append(beside_A, [contour], axis=0)
            else:
                beside_B = np.append(beside_B, [contour], axis=0)

        # raise dim
        beside_A = np.expand_dims(beside_A, axis=1)
        beside_B = np.expand_dims(beside_B, axis=1)

        return beside_A, beside_B

    # Filter out the average value within one standard deviation
    def _average_distance(self, distance_list: list) -> float:
        """
        計算距離列表的平均值，並過濾掉一個標準差以外的值。

        參數:
            distance_list (list): 距離列表。

        返回:
            float: 過濾後的平均距離，若無有效數據則返回 None。
        """
        mean = np.mean(distance_list)
        std = np.std(distance_list)

        filtered_list = [d for d in distance_list if (
            mean - std) <= d <= (mean + std)]

        if filtered_list:
            return round(np.mean(filtered_list), 2)
        else:
            return None

---------------------------------------------------------------------------

utils/tools.py

import cv2
import os
import json
import logging
import datetime
import numpy as np
from tkinter import messagebox
import yaml


# Draw a box with various components on the given image.


def draw_box(image: np.ndarray, center_point: tuple, box_num: int = 1,
             circle_rgb: tuple = (221, 221, 221),
             rectangle_rgb: tuple = (221, 221, 221),
             text_rgb: tuple = (221, 221, 221),
             frame_size: int = 100, direction: any = None):
    """
    在圖像上繪製一個框，包括中心點、矩形框、方向線和文本。

    參數:
        image (np.ndarray): 要繪製的圖像。
        center_point (Tuple[int, int]): 框的中心點座標。
        box_num (int): 框的編號（默認為 1）。
        circle_rgb (Tuple[int, int, int]): 中心點圓圈的顏色（默認為灰色）。
        rectangle_rgb (Tuple[int, int, int]): 矩形框的顏色（默認為灰色）。
        text_rgb (Tuple[int, int, int]): 文本顏色（默認為灰色）。
        frame_size (int): 框的尺寸（默認為 100）。
        direction (Optional[str]): 方向線的類型（可選值："Vertical"、"Horizontal"、"Positive Slope"、"Negative Slope"）。
    """
    cv2.circle(image, tuple(center_point), 5, circle_rgb, -1)

    top_left = (center_point[0] - frame_size // 2,
                center_point[1] - frame_size // 2)
    bottom_right = (center_point[0] + frame_size //
                    2, center_point[1] + frame_size // 2)
    cv2.rectangle(image, top_left, bottom_right, rectangle_rgb, 1)

    if direction is not None:
        draw_line(image, center_point, direction, frame_size)

    text_x = top_left[0] + 5
    text_y = top_left[1] + 20
    cv2.putText(image, str(box_num+1), (text_x, text_y),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_rgb, 2, cv2.LINE_AA)


def draw_line(image: np.ndarray, center_point: tuple, direction: str, box_size: int):
    """
    根據方向在圖像上繪製一條直線。

    參數:
        image (np.ndarray): 要繪製的圖像。
        center_point (Tuple[int, int]): 框的中心點座標。
        direction (str): 方向線的類型（可選值："Vertical"、"Horizontal"、"Positive Slope"、"Negative Slope"）。
        box_size (int): 框的尺寸。
    """
    x, y = center_point
    half_size = box_size // 2
    if direction == "Vertical":
        cv2.line(image, (x, y - half_size),
                 (x, y + half_size), (221, 221, 221), 2)
    elif direction == "Horizontal":
        cv2.line(image, (x - half_size, y),
                 (x + half_size, y), (221, 221, 221), 2)
    elif direction == "Positive Slope":
        cv2.line(image, (x - half_size, y + half_size),
                 (x + half_size, y - half_size), (221, 221, 221), 2)
    elif direction == "Negative Slope":
        cv2.line(image, (x - half_size, y - half_size),
                 (x + half_size, y + half_size), (221, 221, 221), 2)


def draw_helf_line(image: np.ndarray, center: tuple, direction: str, box_size: int):
    """
    在圖像上根據方向繪製半條線。

    參數:
        image (np.ndarray): 要繪製的圖像。
        center (Tuple[int, int]): 框的中心點座標。
        direction (str): 方向線的類型（可選值："Horizontal"、"Vertical"、"Positive Slope"、"Negative Slope"）。
        box_size (int): 框的尺寸。
    """
    x, y = center
    half_len = box_size // 2
    color1 = (255, 0, 0)  # Red for line1
    color2 = (0, 0, 255)  # Blue for line2

    if direction == 'Horizontal':
        cv2.line(image, (x, y-half_len), (x, y), color1, 1)
        cv2.line(image, (x, y), (x, y+half_len), color2, 1)
    elif direction == 'Vertical':
        cv2.line(image, (x-half_len, y), (x, y), color1, 1)
        cv2.line(image, (x, y), (x+half_len, y), color2, 1)
    elif direction == 'Positive Slope':
        for i in range(half_len):
            if 0 <= y-i < image.shape[0] and 0 <= x-i < image.shape[1]:
                image[y-i, x-i] = color1
            if 0 <= y+i < image.shape[0] and 0 <= x+i < image.shape[1]:
                image[y+i, x+i] = color2
    elif direction == 'Negative Slope':
        for i in range(half_len):
            if 0 <= y+i < image.shape[0] and 0 <= x-i < image.shape[1]:
                image[y+i, x-i] = color1
            if 0 <= y-i < image.shape[0] and 0 <= x+i < image.shape[1]:
                image[y-i, x+i] = color2


# Initialization, loading, and saving functions for handling points and directions data.


def load_box(image_ID: str, json_path: str) -> tuple:
    """
    從 JSON 文件中加載框的座標和方向。

    參數:
        image_ID (str): 圖像的唯一標識符。
        json_path (str): JSON 文件的路徑。

    返回:
        Tuple[List[Tuple[int, int]], List[Optional[str]]]: 包含點座標和方向的元組。
    """
    if os.path.exists(json_path):
        with open(json_path, 'r') as json_file:
            points_dict = json.load(json_file)
            if image_ID in points_dict:
                return points_dict[image_ID]["points"], points_dict[image_ID]["directions"]
            else:
                raise KeyError(
                    f"Not found {image_ID} model data. Please excute [run_settings_box.py] first.")

    else:
        raise KeyError(
            f"JSON file not found at {json_path}")


def save_json(points: list, directions: list, image_ID: str, json_path: str):
    """
    將框的座標和方向保存到 JSON 文件中。

    參數:
        points (List[Tuple[int, int]]): 框的中心點座標。
        directions (List[Optional[str]]): 框的方向。
        image_ID (str): 圖像的唯一標識符。
        json_path (str): JSON 文件的路徑。
    """
    points_dict = {}

    if os.path.exists(json_path):
        with open(json_path, 'r') as json_file:
            points_dict = json.load(json_file)

    points_dict[image_ID] = {
        "points": points,
        "directions": directions
    }
    with open(json_path, 'w') as json_file:
        json.dump(points_dict, json_file, indent=4)
    print()
    print("Points saved to [config/].")


def get_img_Model(img_name: str) -> str:
    """
    從圖像文件名中提取模型名稱。

    參數:
        img_name (str): 圖像文件名。

    返回:
        str: 模型名稱。
    """
    underscore_index = img_name.find('_')

    desired_string = img_name[:underscore_index][-5:]

    return desired_string


def setting_init_log(logs_dir: str, logs_name: str):
    """
    設置日誌記錄的配置。

    參數:
        logs_dir (str): 日誌文件夾的路徑。
        logs_name (str): 日誌文件名。
    """
    # Check if logs folder exists, if not, create it
    if not os.path.exists(logs_dir):
        os.makedirs(logs_dir)

    # Create a FileHandler for logging
    logs_path = os.path.join(logs_dir, logs_name)
    logger = logging.getLogger()  # Get the root logger
    logger.setLevel(logging.INFO)

    # Remove all handlers associated with the root logger
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)

    # Create a new FileHandler
    file_handler = logging.FileHandler(logs_path)
    file_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(message)s')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    # Log current time
    now = datetime.datetime.now(
        tz=datetime.timezone(datetime.timedelta(hours=8)))
    logging.info(now.strftime(' [ %Y/%m/%d %H:%M:%S ]\n'))


# Determine the legality of a location in the box


def is_circle_white(image: np.ndarray, center: tuple, radius: int = 5) -> bool:
    """
    檢查框的中心點是否位於白色區域內。

    參數:
        image (np.ndarray): 圖像。
        center (Tuple[int, int]): 圓心座標。
        radius (int): 圓的半徑（默認為 5）。

    返回:
        bool: 圓心是否位於白色區域內。
    """

    height, width = image.shape[:2]
    if center[0] < 0 or center[0] >= width or center[1] < 0 or center[1] >= height:
        return False

    # Get region of the circle
    x_min = max(0, center[0] - radius)
    x_max = min(width - 1, center[0] + radius)
    y_min = max(0, center[1] - radius)
    y_max = min(height - 1, center[1] + radius)

    # Check if all pixels in the circle region are white
    for y in range(y_min, y_max + 1):
        for x in range(x_min, x_max + 1):
            if np.array_equal(image[y, x], [255, 255, 255]):
                continue
            else:
                return False

    return True


def is_black_line(image: np.ndarray, center: tuple, direction: str, len_size: int,
                  min_black_line_threadhld: float = 0.2) -> bool:
    """
    檢查圖像中是否存在超過 N% 的黑色線條。

    參數:
        image (np.ndarray): 圖像。
        center (Tuple[int, int]): 框的中心點座標。
        direction (str): 方向線的類型（可選值："Horizontal"、"Vertical"、"Positive Slope"、"Negative Slope"）。
        len_size (int): 線條的長度。
        min_black_line_threadhld (float): 黑色線條的閾值比例（默認為 0.2）。

    返回:
        bool: 是否存在足夠比例的黑色線條。
    """
    x, y = center
    half_len = len_size // 2

    if direction == 'Horizontal':
        line1 = image[y-half_len:y, x]
        line2 = image[y:y+half_len, x]
    elif direction == 'Vertical':
        line1 = image[y, x-half_len:x]
        line2 = image[y, x:x+half_len]
    elif direction == 'Positive Slope':
        line1 = np.array([image[y-i, x-i] for i in range(half_len)
                         if 0 <= y-i < image.shape[0] and 0 <= x-i < image.shape[1]])
        line2 = np.array([image[y+i, x+i] for i in range(half_len)
                         if 0 <= y+i < image.shape[0] and 0 <= x+i < image.shape[1]])
    elif direction == 'Negative Slope':
        line1 = np.array([image[y+i, x-i] for i in range(half_len)
                         if 0 <= y+i < image.shape[0] and 0 <= x-i < image.shape[1]])
        line2 = np.array([image[y-i, x+i] for i in range(half_len)
                         if 0 <= y-i < image.shape[0] and 0 <= x+i < image.shape[1]])
    else:
        raise ValueError('Invalid direction')

    def is_black_segment(segment):
        black_pixels = np.sum(segment == 0)
        total_pixels = segment.size
        # print(black_pixels, ",", total_pixels,
        #       "=>", black_pixels / total_pixels)
        return black_pixels / total_pixels >= min_black_line_threadhld

    return is_black_segment(line1) and is_black_segment(line2)


def has_sufficient_black_pixels(box: np.ndarray, threshold: float) -> bool:
    """
    確認圖像區域中有超過 N% 的黑色像素。

    參數:
        box (np.ndarray): 要檢查的區域。
        threshold (float): 黑色像素的閾值比例。

    返回:
        bool: 是否存在足夠比例的黑色像素。
    """
    if box.size == 0:
        return False
    total_pixels = box.size
    black_pixels = np.sum(box == 0)
    black_ratio = black_pixels / total_pixels
    return black_ratio > threshold


def is_overlapping(new_box: tuple, existing_boxes: list,
                   box_size: int, max_overlap: float) -> bool:
    """
    檢查新框與現有框是否重疊超過指定比例。

    參數:
        new_box (Tuple[int, int]): 新框的座標。
        existing_boxes (List[Tuple[int, int]]): 現有框的座標。
        box_size (int): 框的尺寸。
        max_overlap (float): 最大重疊比例（百分比）。

    返回:
        bool: 是否存在過多的重疊。
    """
    new_x, new_y = new_box
    box_area = box_size * box_size

    for (x, y) in existing_boxes:
        # Determine coordinates of the intersection rectangle
        x1 = max(new_x, x)
        y1 = max(new_y, y)
        x2 = min(new_x + box_size, x + box_size)
        y2 = min(new_y + box_size, y + box_size)

        # Calculate area of intersection rectangle
        intersection_area = max(0, x2 - x1) * max(0, y2 - y1)
        new_box_area = box_area

        overlap_percentage = (intersection_area / new_box_area) * 100

        if overlap_percentage > max_overlap:
            return True

    return False


def calculate_overlapping(rx: int, ry: int, r_size: int, ex: int, ey: int, e_size: int) -> int:
    """
    計算兩個框的重疊面積。

    參數:
        rx (int): 新框的左上角 x 座標。
        ry (int): 新框的左上角 y 座標。
        r_size (int): 新框的尺寸。
        ex (int): 現有框的左上角 x 座標。
        ey (int): 現有框的左上角 y 座標。
        e_size (int): 現有框的尺寸。

    返回:
        int: 重疊面積。
    """
    ix = max(rx, ex)
    iy = max(ry, ey)
    ax = min(rx + r_size, ex + e_size)
    ay = min(ry + r_size, ey + e_size)

    # Calculate width and height of overlap area
    if ix < ax and iy < ay:
        overlap_width = ax - ix
        overlap_height = ay - iy
        overlap_area = overlap_width * overlap_height
    else:
        overlap_area = 0  # No overlap

    return overlap_area


def get_max_contour(image: np.ndarray, point: tuple, adj_size: int) -> any:
    """
    獲取指定點附近區域的最大輪廓。

    參數:
        image (np.ndarray): 圖像。
        point (Tuple[int, int]): 中心點座標。
        adj_size (int): 區域的尺寸。

    返回:
        Optional[np.ndarray]: 最大輪廓。
    """
    top_x = point[0]-adj_size//2
    top_y = point[1]-adj_size//2

    box = image[top_y:top_y + adj_size,
                top_x:top_x + adj_size]
    # max contours
    contours, _ = cv2.findContours(
        box, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    max_contour = None
    if len(contours) > 0:
        max_contour = max(contours, key=cv2.contourArea)

    return max_contour


def calculate_point(A: tuple, B: tuple, C: tuple) -> tuple:
    """
    計算點 A 到直線 BC 的最短距離。

    參數:
        A (Tuple[int, int]): 點 A 的座標。
        B (Tuple[int, int]): 直線 BC 上的點 B 的座標。
        C (Tuple[int, int]): 直線 BC 上的點 C 的座標。

    返回:
        Tuple[Tuple[int, int], float]: 點到直線的最短距離和距離座標。
    """
    A = np.array(A)
    B = np.array(B)
    C = np.array(C)

    BC = C - B
    BA = A - B

    t = np.dot(BA, BC) / np.dot(BC, BC)
    t = max(0, min(1, t))

    P = B + t * BC

    distance = np.round(np.linalg.norm(P - A), 2)
    return tuple(P.astype(int)), distance

# UI setting


def center_window(window: any) -> None:
    """
    設置窗口居中顯示。

    參數:
        window (Tk): Tkinter 窗口。
    """
    window.update_idletasks()
    width = window.winfo_width()
    height = window.winfo_height()
    x = (window.winfo_screenwidth() // 2) - (width // 2)
    y = (window.winfo_screenheight() // 2) - (height // 2)
    window.geometry(f'{width}x{height}+{x}+{y}')


def save_config(config: dict, showbox: bool = True) -> None:
    """
    保存配置到 YAML 文件。

    參數:
        config (dict): 配置字典。
        showbox (bool): 是否顯示保存提示框（默認為 True）。
    """
    config_path = 'config/config.yaml'
    with open(config_path, 'w') as config_file:
        yaml.dump(config, config_file)
    if showbox:
        messagebox.showinfo("Saved", "Configuration has been saved!")
